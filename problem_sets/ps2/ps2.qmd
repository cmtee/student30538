---
title: "30538 Problem Set 2: Parking Tickets"
author: "Your Name Here"
date: "the date"
format: 
    pdf: 
        include-in-header:
            text: |
                \usepackage{fvextra}
                \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
---

1. "This submission is my work alone and complies with the 30538 integrity
policy." Add your initials to indicate your agreement: *CT*
2. "I have uploaded the names of anyone I worked with on the problem set **[here](https://docs.google.com/forms/d/1-zzHx762odGlpVWtgdIC55vqF-j3gqdAp6Pno1rIGK0/edit)**"  \*\*\_\_\*\* (1 point)
3. Late coins used this pset: \*\*\_\_*\* Late coins left after submission: *3*
4. Knit your `ps2.qmd` to make `ps2.pdf`. 
    * The PDF should not be more than 25 pages. Use `head()` and re-size figures when appropriate. 
5. Push  `ps2.qmd` and `ps2.pdf` to your github repo. It is fine to use Github Desktop.
6. Submit `ps2.pdf` via Gradescope (4 points) 
7. Tag your submission in Gradescope

```{python}
import pandas as pd
import altair as alt
alt.renderers.enable("png")
import time
from vega_datasets import data as vega_data
import warnings 
warnings.filterwarnings('ignore')
```


### Data cleaning continued (15 points)

Reading in one percent sample 
```{python}
# Reading in file
file_path = r'C:\Users\clari\OneDrive\Documents\Python II\student30538\problem_sets\ps2\data\parking_tickets_one_percent.csv'
df = pd.read_csv(file_path)
```

## 1.1
Function to create a 2 col dataframe (COl1 = variable name, col2 = num of times the col is NA)
```{python}
def count_nas(df):
    na_counts = df.isna().sum().reset_index()
    na_counts.columns = ['Variable', 'NA_Count']
    return na_counts.set_index('Variable')
two_col_df = count_nas(df)

print(two_col_df)
```

https://saturncloud.io/blog/how-to-count-the-number-of-missingnan-values-in-each-row-in-python-pandas/#:~:text=(axis%3D1)-,To%20count%20the%20number%20of%20missing%2FNaN%20values%20in%20each,True%20values%20in%20each%20row.

## 1.2
Three variables are missing much more frequently than the others. Why? (Hint: look at some rows and read the data dictionary written by ProPublica)

```{python}
descending_two_col_df = two_col_df.sort_values(by='NA_Count', ascending=False)
print(descending_two_col_df)
```

Hearing disposition (259899), notice _level (84068), and zipcode(54115) tend to have the most NA Values
[EXPLAIN WHY]

## 1.3
Through visual inspection:
The old code is:0976170
The new code:0964125 and 964125B

```{python}
# Filtering for anything that contains "NO STICKER"
filtered_violations = df[df['violation_description'].str.contains(
    'NO CITY STICKER')]

# Get the unique violation codes
violation_codes = filtered_violations['violation_code'].unique().tolist()

print("Violation codes for 'NO CITY STICKER':")
print(violation_codes)
```

From this, I see that 0976170 is a different code number.

## 1.4
```{python}
# New df filtered for violation codes for no sticker, retaining issue date, violation code, fine levels
violation_fines = filtered_violations[filtered_violations['violation_code'].isin(
    ['0964125', '0964125B', '976170'])][['issue_date', 'violation_code', 'fine_level1_amount', 'fine_level2_amount']]
print(violation_fines)

# Putting it in descending order to check for new rate
violation_fines_descending = violation_fines.sort_values(
    by='fine_level2_amount', ascending=False)
print(violation_fines_descending)

# Putting it in descending order to check for old rate
violation_fines_ascending = violation_fines.sort_values(
    by='fine_level2_amount')
print(violation_fines_ascending)
```

The old fine value for level1 is 120
The new fine value for level1 is 200
The old fine value for level2 is 240
The new fine value for level2 is 400

### Revenue increase from “missing city sticker” tickets (20 Points)

2.1 Using pandas, create a new value for violation codes which combines the two codes that you found in the previous question.

```{python}
# Creating a new value to combine the sticker violation
merged_sticker_violations = df.copy()

# Replace the 2 diff sticker violation codes with the new code
merged_sticker_violations['violation_code'] = merged_sticker_violations['violation_code'].replace({
    '0976170': '012345',
    '0964125': '012345',
    '0964125B': '012345'
})

print(merged_sticker_violations)
```

Collapse the data to capture the number of missing city sticker tickets by month

```{python}
# New df with the new violation code, retaining issue date, violation code and ticket queue columns

sticker_violations_monthly = merged_sticker_violations[merged_sticker_violations['violation_code'].isin(
    ['012345'])][['issue_date', 'violation_code', 'ticket_queue']]
sticker_violations_monthly['issue_date'] = pd.to_datetime(
    sticker_violations_monthly['issue_date'])

# Monthly aggregation
sticker_violations_dt = sticker_violations_monthly.groupby(
    sticker_violations_monthly['issue_date'].dt.to_period('M').dt.to_timestamp()).size().reset_index(name="count")
```


Then, using Altair, plot the numberof tickets over time.

```{python}

# Plotting itckets over time
total_sticker_violations = alt.Chart(sticker_violations_dt).mark_line(point=True).encode(
    x=alt.X('yearmonth(issue_date):T', 
            title='Date',
            axis=alt.Axis(format='%b %Y', labelAngle=-45, labelOverlap=False)),
    y=alt.Y('count:Q', 
            title='Number of Violations',
            scale=alt.Scale(zero=False))
).properties(
    title='Monthly Sticker Violations',
    width=800,
    height=400
).interactive()

# Display the chart
total_sticker_violations
```


2.2
Suppose that your reader wants to be able to use the plot to deduce when the price
increase occurred. Add frequent or custom date labels on the x-axis of your plot such
that the date of the price increase is readily apparent. We haven’t covered Altair’s
date labeling features in class so you’ll first need to find the relevant help page in the
documentation. Which help page did you use?

```{python}
# Adding the price increase line at Feb 25, 2024. This is based on the data, where
# we see that 02/25 is the first date of issue with the new code and 02/24 of the previous year
# was the last day of issue using the old code.
base_chart = alt.Chart(sticker_violations_dt).mark_line(point=True).encode(
    x=alt.X('yearmonth(issue_date):T', 
            title='Date',
            axis=alt.Axis(format='%b %Y', labelAngle=-45, labelOverlap=False)),
    y=alt.Y('count:Q', 
            title='Number of Violations',
            scale=alt.Scale(zero=False))
)

# Create a vertical line for Feb 25, 2012
vertical_line = alt.Chart(pd.DataFrame({'date': ['2012-02-25']})).mark_rule(
    color='red',
    strokeWidth=2
).encode(
    x='yearmonth(date):T'
)

# Create a label for the vertical line
label = alt.Chart(pd.DataFrame({'date': ['2012-02-25'], 'label': ['Feb 25, 2012']})).mark_text(
    align='left',
    baseline='bottom',
    dy=-150  # Adjust this value to position the label vertically
).encode(
    x='yearmonth(date):T',
    text='label'
)

# Combine all elements
total_sticker_violations = (base_chart + vertical_line + label).properties(
    title='Monthly Sticker Violations',
    width=800,
    height=400
).interactive()

# Display the chart
total_sticker_violations

```

I used the altair website guide in mark_rule section and applied the logic
https://altair-viz.github.io/gallery/bar_chart_with_mean_line.html


2.3 
```{python}
# Folter
sticker_violations_2011 = (
    sticker_violations_dt[sticker_violations_dt['issue_date'].dt.year == 2011])

sticker_violations_2011['count'].sum()

```

There were 1935 observations

https://sparkbyexamples.com/pandas/pandas-filter-dataframe-rows-on-dates/#:~:text=Filter%20Rows%20by%20Dates%20in%20Pandas%20DataFrame,-If%20you%20have&text=to_datetime()%20you%20can%20just,data%20type%20of%20all%20columns.


```{python}
prediction_2011 = 1935 * 100 * (80)
print(
    f'They should have predicted an increase of {prediction_2011} USD in revenue')
```

*need to add some commas

2.4
```{python}
sticker_violations_2013 = sticker_violations_monthly[
    sticker_violations_monthly['issue_date'].dt.year == 2013]

issued_2013 = sticker_violations_2013['ticket_queue'].count()

print(issued_2013)
# Count paid tickets for 2013
paid_2013 = sticker_violations_2013[sticker_violations_2013["ticket_queue"]
                                    == "Paid"]['ticket_queue'].count()

# Calculate ticket payment rate
ticket_pay_rate_2013 = (paid_2013 / issued_2013) * 100

# Calculate ticket payment rate
ticket_pay_rate_2013 = (paid_2013 / issued_2013) * 100

print(round(40.59213089209194,2))

```

The ticket pay rate is 40.59% in 2013.

```{python}
# Using the 2011 number of tickets issued = 1935
prediction_2013_repayment_rate = 1935 * 40.59 *100
prediction_2013_repayment_rate = '{:,.2f}'.format(prediction_2013_repayment_rate)


print(f'Assuming the number of tickets issued remained the same '
      f'while we use the 2013 repayment rate, then the revenue '
      f'change should have been predicted to be ${prediction_2013_repayment_rate}')
```

2.5
Make a plot with the repayment rates on “missing city sticker” tickets and a vertical line at when the new policy was introduced. Interpret.

```{python}

# Creating a loop function to get the repayment rates
years = range(sticker_violations_monthly['issue_date'].dt.year.min(), 
              sticker_violations_monthly['issue_date'].dt.year.max() + 1)

repayment_rates = []

for year in years:
    sticker_violations_year = sticker_violations_monthly[
        sticker_violations_monthly['issue_date'].dt.year == year]
    
    issued = sticker_violations_year['ticket_queue'].count()
    paid = sticker_violations_year[sticker_violations_year["ticket_queue"] == "Paid"]['ticket_queue'].count()
    
    repayment_rate = (paid / issued) * 100 if issued > 0 else 0
    repayment_rates.append({'year': year, 'repayment_rate': repayment_rate})

# Create DataFrame from the results
df_repayment = pd.DataFrame(repayment_rates)

```

```{python}
# Create the Altair chart
repayment_rates_chart = alt.Chart(df_repayment).mark_line(point=True).encode(
    x=alt.X('year:O', title='Year'),
    y=alt.Y('repayment_rate:Q', title='Repayment Rate (%)', scale=alt.Scale(zero=False)),
    tooltip=['year', alt.Tooltip('repayment_rate:Q', format='.2f')]
).properties(
    title='Repayment Rates for "Missing City Sticker" Tickets',
    width=800,
    height=400
)

# Add vertical line for policy introduction (assuming it was introduced in 2012)
policy_line = alt.Chart(pd.DataFrame({'year': [2012]})).mark_rule(color='red').encode(
    x='year:O'
)

# Add text annotation for the policy line
policy_text = alt.Chart(pd.DataFrame({'year': [2012], 'text': ['New Policy Introduced']})).mark_text(
    align='left',
    baseline='top',
    dx=5,
    dy=-5
).encode(
    x='year:O',
    text='text'
)

# Combine the chart elements
repayment_rates_chart = (repayment_rates_chart + policy_line + policy_text).interactive()

# Display the chart
repayment_rates_chart
```


2.6
Suppose that the City Clerk were committed to getting more revenue from tickets. What
three violation types would you as an analyst have recommended they increase the price
of? Consider both the number of tickets issued for each violation type and the repayment
rate for each violation type. You may assume there is no behavioral response to price
changes (ie. people continue to commit violations at the same rate and repay at the same
rate). Make a plot to support your argument and explain in writing why it supports
your argument.


```{python}
# Calculate the issue count and repayment rates
total_tickets = df['violation_description'].value_counts().reset_index()
total_tickets.columns = ['violation_description', 'total_tickets']

repayment_rates_by_type = df.groupby('violation_description').apply(
    lambda x: (x['ticket_queue'] == 'Paid').sum() / len(x) * 100
).reset_index()
repayment_rates_by_type.columns = ['violation_description', 'repayment_rate']

# Merge the issue counts with repayment rates
result = pd.merge(total_tickets, repayment_rates_by_type, on='violation_description')

# Calculate expected revenue
result['expected_revenue'] = result['total_tickets'] * result['repayment_rate']

# Format the table
final_table = result[['violation_description', 'total_tickets', 'repayment_rate', 'expected_revenue']]
final_table['repayment_rate'] = final_table['repayment_rate'].round(2)
final_table['expected_revenue'] = final_table['expected_revenue'].round(2)

# Sort by expected revenue in descending order
final_table = final_table.sort_values('expected_revenue', ascending=False)

# Display the final table
print(final_table)

final_table['expected_revenue'] = final_table['expected_revenue'].astype(float)

# Find the row with the highest expected revenue
highest_revenue_row = final_table.loc[final_table['expected_revenue'].idxmax()]

# Get the name of the violation with the highest expected revenue
highest_revenue_violation = highest_revenue_row['violation_description']

print(f"The violation with the highest expected revenue is: {highest_revenue_violation}")
print(f"Details of this violation:")
print(highest_revenue_row)
```
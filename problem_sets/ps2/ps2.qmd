---
title: "30538 Problem Set 2: Parking Tickets"
author: "Your Name Here"
date: "the date"
format: 
    html: 
        include-in-header:
            text: |
                \usepackage{fvextra}
                \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
---

1. "This submission is my work alone and complies with the 30538 integrity
policy." Add your initials to indicate your agreement: *CT*
2. "I have uploaded the names of anyone I worked with on the problem set **[here](https://docs.google.com/forms/d/1-zzHx762odGlpVWtgdIC55vqF-j3gqdAp6Pno1rIGK0/edit)**"  \*\*\_\_\*\* (1 point)
3. Late coins used this pset: \*\*\_\_*\* Late coins left after submission: *3*
4. Knit your `ps2.qmd` to make `ps2.pdf`. 
    * The PDF should not be more than 25 pages. Use `head()` and re-size figures when appropriate. 
5. Push  `ps2.qmd` and `ps2.pdf` to your github repo. It is fine to use Github Desktop.
6. Submit `ps2.pdf` via Gradescope (4 points) 
7. Tag your submission in Gradescope

```{python}
import pandas as pd
import altair as alt
alt.renderers.enable("png")
import time
from vega_datasets import data as vega_data
import warnings 
warnings.filterwarnings('ignore')
```


### Data cleaning continued (15 points)

Reading in one percent sample 
```{python}
# Reading in file
file_path = r'C:\Users\clari\OneDrive\Documents\Python II\student30538\problem_sets\ps2\data\parking_tickets_one_percent.csv'
df = pd.read_csv(file_path)
```

## 1.1
Function to create a 2 col dataframe (COl1 = variable name, col2 = num of times the col is NA)
```{python}
def count_nas(df):
    na_counts = df.isna().sum().reset_index()
    na_counts.columns = ['Variable', 'NA_Count']
    return na_counts.set_index('Variable')
two_col_df = count_nas(df)

print(two_col_df)
```

https://saturncloud.io/blog/how-to-count-the-number-of-missingnan-values-in-each-row-in-python-pandas/#:~:text=(axis%3D1)-,To%20count%20the%20number%20of%20missing%2FNaN%20values%20in%20each,True%20values%20in%20each%20row.

## 1.2
Three variables are missing much more frequently than the others. Why? (Hint: look at some rows and read the data dictionary written by ProPublica)

```{python}
descending_two_col_df = two_col_df.sort_values(by='NA_Count', ascending=False)
print(descending_two_col_df)
```

Hearing disposition (259899), notice _level (84068), and zipcode(54115) tend to have the most NA Values
[EXPLAIN WHY]

## 1.3
Through visual inspection:
The old code is:0976170
The new code:0964125 and 964125B

```{python}
# Filtering for anything that contains "NO STICKER"
filtered_violations = df[df['violation_description'].str.contains(
    'NO CITY STICKER')]

# Get the unique violation codes
violation_codes = filtered_violations['violation_code'].unique().tolist()

print("Violation codes for 'NO CITY STICKER':")
print(violation_codes)
```

From this, I see that 0976170 is a different code number.

## 1.4
```{python}
# New df filtered for violation codes for no sticker, retaining issue date, violation code, fine levels
violation_fines = filtered_violations[filtered_violations['violation_code'].isin(
    ['0964125', '0964125B', '976170'])][['issue_date', 'violation_code', 'fine_level1_amount', 'fine_level2_amount']]
print(violation_fines)

# Putting it in descending order to check for new rate
violation_fines_descending = violation_fines.sort_values(
    by='fine_level2_amount', ascending=False)
print(violation_fines_descending)

# Putting it in descending order to check for old rate
violation_fines_ascending = violation_fines.sort_values(
    by='fine_level2_amount')
print(violation_fines_ascending)
```

The old fine value for level1 is 120
The new fine value for level1 is 200
The old fine value for level2 is 240
The new fine value for level2 is 400

### Revenue increase from “missing city sticker” tickets (20 Points)

2.1 Using pandas, create a new value for violation codes which combines the two codes that you found in the previous question.

```{python}
# Creating a new value to combine the sticker violation
merged_sticker_violations = df.copy()

# Replace the 2 diff sticker violation codes with the new code
merged_sticker_violations['violation_code'] = merged_sticker_violations['violation_code'].replace({
    '0976170': '012345',
    '0964125': '012345',
    '0964125B': '012345'
})

print(merged_sticker_violations)
```

Collapse the data to capture the number of missing city sticker tickets by month

```{python}
# New df with the new violation code, retaining issue date, violation code and ticket queue columns

sticker_violations_monthly = merged_sticker_violations[merged_sticker_violations['violation_code'].isin(
    ['012345'])][['issue_date', 'violation_code', 'ticket_queue']]
sticker_violations_monthly['issue_date'] = pd.to_datetime(
    sticker_violations_monthly['issue_date'])

# Monthly aggregation
sticker_violations_dt = sticker_violations_monthly.groupby(
    sticker_violations_monthly['issue_date'].dt.to_period('M').dt.to_timestamp()).size().reset_index(name="count")
```


Then, using Altair, plot the numberof tickets over time.

```{python}

# Plotting itckets over time
total_sticker_violations = alt.Chart(sticker_violations_dt).mark_line(point=True).encode(
    x=alt.X('yearmonth(issue_date):T', 
            title='Date',
            axis=alt.Axis(format='%b %Y', labelAngle=-45, labelOverlap=False)),
    y=alt.Y('count:Q', 
            title='Number of Violations',
            scale=alt.Scale(zero=False))
).properties(
    title='Monthly Sticker Violations',
    width=800,
    height=400
).interactive()

# Display the chart
total_sticker_violations
```


2.2
Suppose that your reader wants to be able to use the plot to deduce when the price
increase occurred. Add frequent or custom date labels on the x-axis of your plot such
that the date of the price increase is readily apparent. We haven’t covered Altair’s
date labeling features in class so you’ll first need to find the relevant help page in the
documentation. Which help page did you use?

```{python}
# Adding the price increase line at Feb 25, 2024. This is based on the data, where
# we see that 02/25 is the first date of issue with the new code and 02/24 of the previous year
# was the last day of issue using the old code.
base_chart = alt.Chart(sticker_violations_dt).mark_line(point=True).encode(
    x=alt.X('yearmonth(issue_date):T', 
            title='Date',
            axis=alt.Axis(format='%b %Y', labelAngle=-45, labelOverlap=False)),
    y=alt.Y('count:Q', 
            title='Number of Violations',
            scale=alt.Scale(zero=False))
)

# Create a vertical line for Feb 25, 2012
vertical_line = alt.Chart(pd.DataFrame({'date': ['2012-02-25']})).mark_rule(
    color='red',
    strokeWidth=2
).encode(
    x='yearmonth(date):T'
)

# Create a label for the vertical line
label = alt.Chart(pd.DataFrame({'date': ['2012-02-25'], 'label': ['Feb 25, 2012']})).mark_text(
    align='left',
    baseline='bottom',
    dy=-150  # Adjust this value to position the label vertically
).encode(
    x='yearmonth(date):T',
    text='label'
)

# Combine all elements
total_sticker_violations = (base_chart + vertical_line + label).properties(
    title='Monthly Sticker Violations',
    width=800,
    height=400
).interactive()

# Display the chart
total_sticker_violations

```

I used the altair website guide in mark_rule section and applied the logic
https://altair-viz.github.io/gallery/bar_chart_with_mean_line.html


2.3 
```{python}
# Folter
sticker_violations_2011 = (
    sticker_violations_dt[sticker_violations_dt['issue_date'].dt.year == 2011])

sticker_violations_2011['count'].sum()

```

There were 1935 observations

https://sparkbyexamples.com/pandas/pandas-filter-dataframe-rows-on-dates/#:~:text=Filter%20Rows%20by%20Dates%20in%20Pandas%20DataFrame,-If%20you%20have&text=to_datetime()%20you%20can%20just,data%20type%20of%20all%20columns.


```{python}
prediction_2011 = 1935 * 100 * (80)
print(
    f'They should have predicted an increase of {prediction_2011} USD in revenue')
```

They should have predicted an increase of 15,480,000 USD in revenue

2.4
```{python}
sticker_violations_2013 = sticker_violations_monthly[
    sticker_violations_monthly['issue_date'].dt.year == 2013]

issued_2013 = sticker_violations_2013['ticket_queue'].count()

print(issued_2013)
# Count paid tickets for 2013
paid_2013 = sticker_violations_2013[sticker_violations_2013["ticket_queue"]
                                    == "Paid"]['ticket_queue'].count()

# Calculate ticket payment rate
ticket_pay_rate_2013 = (paid_2013 / issued_2013) * 100


print(round(40.59213089209194,2))

```

The ticket pay rate is 40.59% in 2013.

```{python}
# COunting the 2011 number of tickets issued
sticker_violations_2011 = sticker_violations_monthly[
    sticker_violations_monthly['issue_date'].dt.year == 2011]

issued_2011 = sticker_violations_2011['ticket_queue'].count() * 100
print(f'Tickets issued in 2011 were {issued_2011}')

# Count paid tickets for 2011
paid_2011 = sticker_violations_2011[sticker_violations_2011["ticket_queue"]
                                    == "Paid"]['ticket_queue'].count() * 100

# Calculate ticket payment rate 2011
ticket_pay_rate_2011 = round((paid_2011 / issued_2011) * 100,2)

print(f'The ticket pay rate in 2011 was {ticket_pay_rate_2011}')

# Change in repayment rate
repayment_rate_change = round(ticket_pay_rate_2011 - ticket_pay_rate_2013,2)
print(f'The change in repayment rater is {repayment_rate_change}')

revenue_change_2011_2013 = (193500 * .4059 * 200)-(193500 * .5395 * 120)
formatted_revenue_change_2011_2013 = '{:,.2f}'.format(revenue_change_2011_2013)
revenue_2013 = 193500 * .4059 * 200

print(f"The revenue change between 2011 and 2013 was an increase of ${formatted_revenue_change_2011_2013}")
print (f'The predicted revenue for 2013 would be {revenue_2013} USD')
```

Tickets issued in 2011 were 193500
The ticket pay rate in 2011 was 53.95
The change in repayment rater is 13.36
The revenue change between 2011 and 2013 was an increase of $3,181,140.00
The predicted revenue for 2013 would be 15708329.99 USD


2.5
Make a plot with the repayment rates on “missing city sticker” tickets and a vertical line at when the new policy was introduced. Interpret.

```{python}

# Creating a loop function to get the repayment rates
years = range(sticker_violations_monthly['issue_date'].dt.year.min(), 
              sticker_violations_monthly['issue_date'].dt.year.max() + 1)

repayment_rates = []

for year in years:
    sticker_violations_year = sticker_violations_monthly[
        sticker_violations_monthly['issue_date'].dt.year == year]
    
    issued = sticker_violations_year['ticket_queue'].count()
    paid = sticker_violations_year[sticker_violations_year["ticket_queue"] == "Paid"]['ticket_queue'].count()
    
    repayment_rate = (paid / issued) * 100 if issued > 0 else 0
    repayment_rates.append({'year': year, 'repayment_rate': repayment_rate})

# Create DataFrame from the results
df_repayment = pd.DataFrame(repayment_rates)

```

```{python}
# Create the Altair chart
repayment_rates_chart = alt.Chart(df_repayment).mark_line(point=True).encode(
    x=alt.X('year:O', title='Year'),
    y=alt.Y('repayment_rate:Q', title='Repayment Rate (%)', scale=alt.Scale(zero=False)),
    tooltip=['year', alt.Tooltip('repayment_rate:Q', format='.2f')]
).properties(
    title='Repayment Rates for "Missing City Sticker" Tickets',
    width=800,
    height=400
)

# Add vertical line for policy introduction (assuming it was introduced in 2012)
policy_line = alt.Chart(pd.DataFrame({'year': [2012]})).mark_rule(color='red').encode(
    x='year:O'
)

# Add text annotation for the policy line
policy_text = alt.Chart(pd.DataFrame({'year': [2012], 'text': ['New Policy Introduced']})).mark_text(
    align='left',
    baseline='top',
    dx=5,
    dy=-5
).encode(
    x='year:O',
    text='text'
)

# Combine the chart elements
repayment_rates_chart = (repayment_rates_chart + policy_line + policy_text).interactive()

# Display the chart
repayment_rates_chart
```


2.6
Suppose that the City Clerk were committed to getting more revenue from tickets. What
three violation types would you as an analyst have recommended they increase the price
of? Consider both the number of tickets issued for each violation type and the repayment
rate for each violation type. You may assume there is no behavioral response to price
changes (ie. people continue to commit violations at the same rate and repay at the same
rate). Make a plot to support your argument and explain in writing why it supports
your argument.


```{python}
# Calculate the issue count and repayment rates
total_tickets = df['violation_description'].value_counts().reset_index()
total_tickets.columns = ['violation_description', 'total_tickets']

repayment_rates_by_type = df.groupby('violation_description').apply(
    lambda x: (x['ticket_queue'] == 'Paid').sum() / len(x) * 100
).reset_index()
repayment_rates_by_type.columns = ['violation_description', 'repayment_rate']

# Merge the issue counts with repayment rates
result = pd.merge(total_tickets, repayment_rates_by_type,
                  on='violation_description')

# Calculate expected revenue
result['expected_revenue'] = result['total_tickets'] * result['repayment_rate']

# Format the table
final_table = result[['violation_description',
                      'total_tickets', 'repayment_rate', 'expected_revenue']]
final_table['repayment_rate'] = final_table['repayment_rate'].round(2)
final_table['expected_revenue'] = final_table['expected_revenue'].round(2)

# Sort by expected revenue in descending order
final_table = final_table.sort_values('expected_revenue', ascending=False)

# Display the final table
print(final_table)

final_table['expected_revenue'] = final_table['expected_revenue'].astype(float)

# Find the row with the highest expected revenue
highest_revenue_row = final_table.loc[final_table['expected_revenue'].idxmax()]

# Get the name of the violation with the highest expected revenue
highest_revenue_violation = highest_revenue_row['violation_description']

print(
    f"The violation with the highest expected revenue is: {highest_revenue_violation}")
print(f"Details of this violation:")
print(highest_revenue_row)
```

The violation that would earn the city the most money, given the numnber of 
tickets issued and the repayment rate is EXPIRED PLATES OR TEMPORARY REGISTRATION.
This will lead to an expected revenue of $2,708,200.0

```{python}
# Select the top 10 violations by expected revenue
top_10 = final_table.nlargest(10, 'expected_revenue')

# Create a color scheme for the top 3
top_3_violations = top_10.nlargest(3, 'expected_revenue')['violation_description'].tolist()
domain = top_3_violations + ['Other']
range_ = ['red', 'green', 'blue', 'lightgray']

# Create the scatter plot
chart = alt.Chart(top_10).mark_circle(size=100).encode(
    x=alt.X('violation_description:N', 
            sort='-y', 
            title='Violation Type',
            axis=alt.Axis(labelAngle=-45)),  
    y=alt.Y('expected_revenue:Q', 
            title='Expected Revenue ($)'),
    color=alt.Color('violation_description:N',
                    scale=alt.Scale(domain=domain, range=range_),
                    legend=alt.Legend(title="Violation Description")),
    tooltip=['violation_description:N', 'expected_revenue:Q']
).properties(
    width=800,
    height=400,
    title='Top 10 Violation Types by Expected Revenue'
)

# Display the chart
chart


```

3.

```{python}
df['is_paid'] = df['total_payments'] > 0

violation_summary = df.groupby('violation_description').agg(
    total_tickets=('violation_description', 'size'),  # Count total tickets
    fraction_paid=('is_paid', 'mean'),  # Fraction of tickets that were paid
    avg_fine_level1=('fine_level1_amount', 'mean')  # Average fine level 1 amount
).reset_index()

violation_summary = violation_summary.sort_values(by='total_tickets', ascending=False)

top_5_violation_summary = violation_summary.head(5)

print(top_5_violation_summary)

violation_summary

```


```{python}
# Step 1: Filter for violations that appear at least 100 times
violation_summary_filtered = violation_summary[violation_summary['total_tickets'] >= 100]

# Step 2: Remove the outlier by excluding the violation with the highest average fine
outlier_violation = violation_summary_filtered['avg_fine_level1'].idxmax()
violation_summary_filtered = violation_summary_filtered.drop(outlier_violation)

```



```{python}
# Step 3: Create the scatter plot
# Scatter plot of fine amount vs. fraction paid
scatter = alt.Chart(violation_summary_filtered).mark_point().encode(
    x=alt.X('avg_fine_level1:Q', title='Average Fine Level 1 ($)'),
    y=alt.Y('fraction_paid:Q', title='Fraction of Tickets Paid'),
    tooltip=['violation_description', 'total_tickets', 'avg_fine_level1', 'fraction_paid']
).properties(
    title='Relationship Between Fine Amount and Fraction of Tickets Paid'
)

scatter.display()
```


```{python}
alt.Chart(violation_summary_filtered).mark_boxplot().encode(
    x=alt.X('avg_fine_level1:Q', title='Average Fine Level 1 ($)'),
    y=alt.Y('fraction_paid:Q', title='Fraction of Tickets Paid'),
    tooltip=['violation_description', 'total_tickets', 'avg_fine_level1', 'fraction_paid']
).properties(
    title='Relationship Between Fine Amount and Fraction of Tickets Paid'
)

```


```{python}
 alt.Chart(violation_summary_filtered).mark_bar().encode(
   x=alt.X('avg_fine_level1:Q', title='Average Fine Level 1 ($)'),
    y=alt.Y('fraction_paid:Q', title='Fraction of Tickets Paid'),
    tooltip=['violation_description', 'total_tickets', 'avg_fine_level1', 'fraction_paid']
).properties(
    title='Relationship Between Fine Amount and Fraction of Tickets Paid'
)
```


On the one hand, the boxplot contains a lot of granular and detailed information. On the other hand, I would likely still recommend the scatterplot. It contains what is, in my opinion, the easiest to discern relationship between how fine levels affect amount of tickets paid. 
We see a weak negative correlation, telling us that as fine level increases, ticket payment gradually decreases. While this is perhaps the best 'at-a-glance' data, it's not the most nuanced. There will always be trade-offs with different data styles, but the scatterplot 
prioritizes readability.  